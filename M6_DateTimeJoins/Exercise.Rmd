---
title: "Time, Data and Joins"
output: 
  html_document:
      toc: true
      toc_float: true
      toc_collapsed: true
date: "2024-07-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)

library(tidyverse)
```

# Time and Dates

Alternatively, can load the individual package `library(lubridate)`. 

Links to useful resources: 

 - library website: https://lubridate.tidyverse.org/
 - defining date format: https://r4ds.hadley.nz/datetimes#tbl-date-formats

## Slide Prompts

What math can be done to explain the relationship between `today()` and `as.numeric(today())`?

```{r}
Sys.time()
today()

as.numeric(Sys.time())
as.numeric(today())
```

## Exercise

In this exercise we will clean and manipulate date data. The simulated data set is a line list data related to hospitalization. 

As always, the first step is to figure out where we are starting. 

```{r}

#1. Read in date.csv using base R function read.csv
list_data <- read.csv("data/date.csv")

# let's take a look- here are a view ways we can "look" at the data
View(list_data)
colnames(list_data)
str(list_data)
```

We want all of the columns starting with `date_` to be date data. 

```{r}
#2. Cleaning. Columns starting with date_ are currently characters. 
# convert date_infection string to date
list_data |>
    mutate(date_infection = ymd(date_infection))
# we could repeat the process for the remaining columns 

# -OR-

# A faster method would be to define the columns as dates when they are read into R. If we use readr's `read_csv` what happens? 
list_data <- read_csv("data/date.csv")
# again, let's look at the data
spec(list_data)
# the col starting with date_ are read in as dates since they all follow a standard date format. 

```

Now that the date columns are in the correct data type, let's calculate some intervals. Modify the code chunk below based on the comments


```{r}
#3. Calculate times

#list_data <- #uncomment when you've finished 3a-3c 
    list_data |>
    # 3a. calculate patient age when hospitalized from birth year  
      mutate(age = year(date_hospitalisation) - [ADD CODE]) |>
    # 3b. days between infection, onset, hospitalization
      mutate(time_to_recovery = [ADD CODE],
             incubation_days = [ADD CODE],
             hosp_days = [ADD CODE]) |> 
    # 3c. Convert onset date to EPI week. An epidemiological week (EPI week) is a standardized method for counting weeks that allows for the comparison of data year after year.
      mutate(week_reported = [ADD CODE])

```

## Challenge Exercises

### Challenge Exercise 1: Looking for errors. 

Collecting dates accurately can be hard. How would you go about identifying potential entry errors? 

**Hint: Use the intervals we just calculated**
```{r}
list_data |>
  [ADD CODE]
```


### Challenge Exercise 2

Convert the previous exercise into a function. Assume the the data will always be in the same format including column names

```{r fnc practice}
Processing_List_Data = function(file_name = "data/date.csv"){
  
  d_out <- 
    read_csv(file_name) |>
    [ADD CODE]

  return(d_out)
  }
```

# Joins

Alternatively, can load the individual package `library(dplyr)`

Links to useful resources: 

 - library website: https://lubridate.tidyverse.org/
 - defining date format: https://r4ds.hadley.nz/datetimes#tbl-date-formats

## Slide Prompts 
```{r practice joins}

# Practicing joins
x <- tibble(Patient_ID = c(12,25,72), Diag_Test = c("Y","N","Y"))
y <- tibble(Patient_ID = c(12,72,83), Test_Result = c("Pos","Neg","Neg"))
```

## Exercise

We are now going to work with two additional datasets related to the list_data above. We will work to assemble one large data set. 

What's the first step? Looking at your data!

Since we know we are working towards a join, we need to at least know: 

 - What column is the key?
 - Are all other columns uniquely named? 
 
```{r}
# 1. Read in hospitalization.csv and contact.csv
hos <- read_csv("data/hospitalization.csv") 
con <- read_csv("data/contact.csv")
# 2. Explore data: check col names, etc. in prep for join. 
[ADD CODE]
```

The next step is to decide on the type of join. Since all the column names are unique besides the key, and the data sets are the same size we might guess that each row in one has a corresponding row in the other. 

We can test this using `anti_join()`. Why do I test this theory using `(hos,con)` and `(con, hos)`? 

```{r}
# 3. Join hos and con into a single data set using the appropriate key. What type of join should be used?
# they are the same length, so lets see if they have the same entries.
anti_join(hos, con)
anti_join(con, hos)


#the result of the anti_join(s) is NULL so we can use a any mutating join
con_hos <- 
  hos |> 
  [ADD CODE](con, by = "case_id")

```

It seems like we were sucessful at joining the two data sets. How do we check this?
```{r}

# 4. Sanity checks - did the join do what we wanted
# let's look at column names
spec(con_hos)
# let's look at the number of rows
[ADD CODE]
```

## Challenge Exercises

### Challenge Exercise 1: Joining census data. 

I have downloaded the total population size for 4 states, and some cities within each state. 
You are tasked with calculating the population size in each state excluding the city populations. 

**Hint: Take advantage of the data sets similar column names. **

```{r}
state <- read_csv("data/state.csv")
city <- read_csv("data/city.csv")
```

What's the first step of data wrangling?

```{r}
spec(state)
spec(city)
```

My approach to this problem would be to prep the city data by: 

 1a. Create a common key. The first two numbers of the city GEOID is that same as the state GEOID
 1b. Calculate the total city population for each state (notice Texas has two cities)

The code chunk below is great example of the power of tidyverse. How many different things are being done in a single block? 

```{r}
city_population <- 
  city |>
    #let's hang on to the full GEOID for the city, just rename it "place"
  rename(place = GEOID) |>
  mutate(GEOID = as.numeric(str_extract(place, ".."))) |>
   #create city populations for each state
  group_by(GEOID) |>
  summarise(estimate = [ADD CODE]) |>
   #add a name for clarity
  mutate(NAME = "city")
```

Now that the two data sets have a key in common, they can be joined. What type of join is needed? Will multiple types work?

```{r}
# 2. Use the key to combine city and state data
cs_join <- 
  state |>
     # it is important to include the by argument since they have same column names but different values. 
  [ADD CODE](city_population, by = "GEOID") 

```

Remember the power of tidyverse is in the ability to manipulate columns as if they are vectors. What column needs to be subtracted from the other to end in are target population size?

```{r}

# 3. Use mutate to subtrate the city estimate from the state estimate
cs_join |>
  mutate(state_remaining_population = [ADD CODE])
```

### Challenge Exercise 2: Data manipulation

Returning to the contact data set - What is the off-spring distribution? Does it change with generation? 

Use the comments to guide your code modifications. 

```{r}
con |>
  # 1. add group to turn on by generation calculation
  #group_by(generation) |>
  # 2. count how many time a case_id shows up in the infector column 
  count([ADD CODE]) |>
  # 3. calculate the mean occurance of each infector
  summarise(mean_offspring = [ADD CODE])
```



